**ORALI 30/06**
 1. Local e global interpretability
 2. Cosa vuol dire calibrare una rete neurale (riferimento a B&S model)
 3. Disegna rete neurale con 3 input, 1 layer, 3 neuroni e 1 output. Cosa c’è in ogni pallino e quanti gradi di libertà ci sono (e a cosa sono riferiti)
 4. Cos’è uno smart contract (+ esempio aereo con oracolo etc.)
 5. Proof of stake (Ethereum 2.0, libra)
 6. Exploit/Explore, epsilon greedy, how do you do exploration/exploitation. exploration -> random, exploit -> reward
 7. Cos’è un decision tree e come è costruito. Qual è il ruolo degli hyperparameters (e quali sono, esempi)
 8. Cosa si può fare per risolvere il problema della trust nelle BC o qualcosa di simile relativo alla trust (smart contract (?), ICO (?), risolto dal “consenso” c’è remunerazione/incentivi per lavorare onestamente (proof of work/proof of stake, devi essere onesto cosi viene remunerato e non puoi fare bordello perché tutti devono validare))
 9. 50%+1 attack nella BC, how is it possible? What you have to do?
 10. Problema bizantino e cazzate varie (la storia che ci sono dei nodi disonesti che tentano di far casino, si risolve con il consensus perché la pow devi ottenere il 50%+1 di nodi a favore e quindi fai fatica ad hackerare robe)
 11. Q learning and reinforcement learning
 12. What is unsupervised learning
 13. What is token, how we create it, why we use it
 14. DAO cos’è e come funziona
 15. What is an Hard Fork
 16. What is a random forest
 17. Main measures in order to deal with quality of the classifier (and un’altra roba che non ho capito) -> accuracy, precision, roc curve, etc
 18. Disegna ROC curve e precision recall curve e fai qualcosa (non ho capito cosa) con l’optimal classifier
 19. Metodo Silhouette (valori verso 1 -> cluster ben definiti e ben distanti), metodo con inertia
 20. Immagina di voler fare cluster, per creare i cluster all’inizio come fai? Tieni tutto il dataset o elimini qualche feature? -> Tolgo robe, poi faccio i cluster e poi le riutilizzo
 21. Funzioni di attivazione, sia nell’output sia nei layer. Perché i neuroni le usano? Senza di quelle l’algoritmo sarebbe? Come diventa la rete neurale? -> Diventerebbe un modello lineare (m la realtà non è lineare quindi le funzioni di attivazione servono)
 22. Shapley Values cos’è? -> utilizza principi di game theory, formula matematica, l’output è un numero reale, cosa rappresenta l’output? Valore alto -> feature importante
 23. Cos’è una policy epsilon greedy -> tiene conto sia di exploration sia exploitation -> guardi random tutti gli stati, anche quelli che fanno un po’ schifo sia quelli che non conosco
 24. Cosa sono i cumulative return (reward) e qual è il loro ruolo nel reinforcement learning
 25. Funzioni di attivazione quali usare e perché, fai dei grafici
 26. Information gain nei decision tree -> misure di impurità (entropy e gini index)
 27. Cos’è il regression tree
 28. Cos’è una Soft Fork
 29. Tipologie di classificazione di un token
 30. Cos’è un regression tree
 31. Kmeans
 32. Learning in decision trees
 33. classi di Ethereum (?)
 34. la cazzata che ha provocato hard fork in ethereum
 35. spendability (token)
 
**ALTRI GIORNI**
 1. ICO, DAICO, IEO
 2. Come si costruisce un decision tree?
 3. Come viene valutata la bontà/performance di un modello di classificazione supervised?
 4. Interpretability
 5. Shapley value
 6. Value function e reinforcement learning
 7. Gini index
 8. Metodi di clustering
 9. Iperparametri
 10. K-means e scelta di K
 11. Cos’è una neural network?
 12. Epsilon greedy policy in reinforcement learning
 13. Proof of stake
 14. Random forest
 15. Clustering unsupervised learning + esempi
 16. Stable coin
 17. Classificazione token
 18. Libra (non l’ha mai chiesto esplicitamente ma è stato citato in qualche risposta come esempio)
 19. Exchange (anche questo mai chiesto esplicitamente ma è stato citato)
 20. Fungible tokens
 21. Cos’è omnilayer (è spiegato in una slide da qualche parte)
 22. Cos’è il learning rate (parametro che determina lo step size ad ogni iterazione nel metodo gradiente discendente)